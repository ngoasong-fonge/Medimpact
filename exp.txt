PROD SERVERS
[svcpostgres@pv2medpg1c1 vacuum_analyze]$ /opt/app/python/bin/patronictl -c /opt/app/patroni/patroni.yml list
+ Citus cluster: pgprod1 -------------+--------------+-----------+----+-----------+
| Group | Member      | Host          | Role         | State     | TL | Lag in MB |
+-------+-------------+---------------+--------------+-----------+----+-----------+
|     0 | pv2medpg1c1 | 10.15.130.160 | Leader       | running   | 19 |           |
|     0 | pv2medpg1c2 | 10.15.130.161 | Sync Standby | streaming | 19 |         0 |
|     1 | pv2medpg1w1 | 10.15.130.162 | Leader       | running   | 14 |           |
|     1 | pv2medpg1w2 | 10.15.130.163 | Sync Standby | streaming | 14 |         0 |
|     2 | pv2medpg1w3 | 10.15.130.164 | Leader       | running   | 13 |           |
|     2 | pv2medpg1w4 | 10.15.130.170 | Sync Standby | streaming | 13 |         0 |
+-------+-------------+---------------+--------------+-----------+----+-----------+
Group 0 is managed by coordinator nodes pv2medpg1c1 (Leader) and pv2medpg1c2 (Sync Standby). These coordinator nodes typically manage metadata and query routing for the Citus cluster. They are not responsible for storing data.

Group 1 and Group 2 are worker nodes in the Citus cluster. These worker nodes manage the actual data storage and processing.

Group 1 is managed by worker nodes pv2medpg1w1 (Leader) and pv2medpg1w2 (Sync Standby).
Group 2 is managed by worker nodes pv2medpg1w3 (Leader) and pv2medpg1w4 (Sync Standby).
In this configuration:

Worker nodes within each group are responsible for storing and processing data, and they actively participate in query execution.
The "Leader" worker in each group is the primary node for the data in that group. It actively handles write operations and is the target for read queries.
The "Sync Standby" worker in each group is in a standby state. It replicates data from the leader and is ready to take over as the leader if the leader node fails. This provides high availability and fault tolerance.
The role of worker nodes, both leader and sync standby, is to collectively manage the distributed data across the Citus cluster and to ensure high availability and load distribution while actively participating in query processing.
-----------------------------------------------------------------------------------------------------------------------------------------------
PROD DR SERVERS
[svcpostgres@pv1medpg0c1 group0]$ /opt/app/python/bin/patronictl -c /opt/app/patroni/patroni.yml list
+ Citus cluster: pgproddr1 --------+----------------+-----------+----+-----------+
| Group | Member      | Host       | Role           | State     | TL | Lag in MB |
+-------+-------------+------------+----------------+-----------+----+-----------+
|     0 | pv1medpg0c1 | 10.13.2.21 | Standby Leader | streaming | 17 |           |
|     0 | pv1medpg0c2 | 10.13.2.27 | Replica        | streaming | 17 |         0 |
|     1 | pv1medpg0w1 | 10.13.2.30 | Standby Leader | streaming | 12 |           |
|     1 | pv1medpg0w2 | 10.13.2.31 | Replica        | streaming | 12 |         0 |
|     2 | pv1medpg0w3 | 10.13.2.34 | Standby Leader | streaming | 11 |           |
|     2 | pv1medpg0w4 | 10.13.2.35 | Replica        | streaming | 11 |         0 |
+-------+-------------+------------+----------------+-----------+----+-----------+
The Citus cluster is divided into three groups, labeled as Group 0, Group 1, and Group 2.

Each group consists of two members, one in the "Standby Leader" role and one in the "Replica" role. This is a high-availability configuration for the cluster, where there is a standby leader for each group, and a replica for each standby leader.

The "Standby Leader" members are in a standby state and are ready to take over as the leader in their respective groups if the current leader fails. These standby leaders continuously replicate data and changes from the current leaders to stay in sync.

The "Replica" members are in a replica role and are actively replicating data from their corresponding leader. They serve as hot standby nodes that can take over if the leader fails.

The "State" column indicates that all members are in a "streaming" state, which means they are actively replicating data. This is a healthy state, as it ensures that data is continuously synchronized.

The "TL" (Transaction Log) column shows the current WAL (Write-Ahead Log) position for each member.

The "Lag in MB" column typically shows the replication lag in megabytes, but it appears to be empty, indicating that the replication is up to date, with a lag of 0 MB.

In this setup, each group has redundancy for high availability, with a standby leader that can take over in case of leader failure. The configuration is designed to ensure that the Citus cluster remains highly available and fault-tolerant while actively replicating data to maintain consistency and reliability across all members.


top - 19:21:59 up 105 days, 18:27,  6 users,  load average: 4.19, 4.23, 4.00
Tasks: 352 total,   4 running, 348 sleeping,   0 stopped,   0 zombie
%Cpu(s): 84.1 us, 13.1 sy,  0.0 ni,  0.0 id,  0.2 wa,  1.0 hi,  1.7 si,  0.0 st
MiB Mem :  24078.8 total,    249.5 free,   3231.4 used,  20597.9 buff/cache
MiB Swap:   2048.0 total,   1194.3 free,    853.7 used.  14159.7 avail Mem


2023-11-02 19:55:57.495 UTC [1330076] HINT:  Consider increasing the configuration parameter "max_wal_size".
2023-11-02 19:55:57.495 UTC [1330076] LOG:  checkpoint starting: wal
2023-11-02 19:56:14.970 UTC [1330076] LOG:  checkpoint complete: wrote 61986 buffers (7.9%); 0 WAL file(s) added, 0 removed, 33 recycled; write=17.205 s, sync=0.128 s, total=17.476 s; sync files=15, longest=0.061 s, average=0.009 s; distance=537335 kB, estimate=544704 kB


SELECT datname
    , age(datfrozenxid)
    , current_setting('autovacuum_freeze_max_age')
FROM pg_database
ORDER BY 2 DESC;

SELECT c.oid::regclass
    , age(c.relfrozenxid)
    , pg_size_pretty(pg_total_relation_size(c.oid))
FROM pg_class c
JOIN pg_namespace n on c.relnamespace = n.oid
WHERE relkind IN ('r', 't', 'm')
AND n.nspname NOT IN ('pg_toast')
ORDER BY 2 DESC LIMIT 100;

SELECT n.nspname AS schema_name
    , c.relname AS table_name
    , age(c.relfrozenxid) AS frozen_transaction_age
    , pg_size_pretty(pg_total_relation_size(c.oid)) AS table_size
FROM pg_class c
JOIN pg_namespace n on c.relnamespace = n.oid
WHERE relkind IN ('r', 't', 'm')
AND n.nspname NOT IN ('pg_toast')
ORDER BY frozen_transaction_age DESC
LIMIT 100;



\t \o /tmp/vacuum.sql select 'vacuum freeze analyze verbose ' || oid::regclass || ';' from pg_class where relkind in ('r', 't', 'm') order by age(relfrozenxid) desc limit 100; \o \t \set ECHO all \i /tmp/vacuum.sql

https://www.crunchydata.com/blog/managing-transaction-id-wraparound-in-postgresql


ODBC PostgreSQL Wire Protocol driver]Optional feature not implemented.[Informatica][ODBC PostgreSQL Wire Protocol driver]Driver's SQLSetConnectAttr failed.[Informatica][ODBC PostgreSQL Wire Protocol driver]SSL I/O Error.[Informatica][ODBC PostgreSQL Wire Protocol driver]SSL I/O Error.[Informatica][ODBC PostgreSQL Wire Protocol driver]01006[Informatica][ODBC PostgreSQL Wire Protocol driver]01006
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
In order to better organize the data collection, we suggest you use a temporary directory (indicated below by /tmp/pt/collected/$(hostname), 
but you can use any other at your convenience) to store the data being collected before providing it to us:

PTDEST=/tmp/pt/collected/$(hostname)
mkdir -p ${PTDEST}

The database server's Operating System logs are also a source of valuable information. 
Please attach your current log file and anything historical in this context that may prove useful:

cp /var/log/{messages,syslog} ${PTDEST}/

journalctl -e > ${PTDEST}/journal.out

sudo dmesg -T > ${PTDEST}/dmesg.out

curl -LO https://raw.githubusercontent.com/percona/support-snippets/master/postgresql/pg_gather/gather.sql
psql <connection_parameters_if_any> -d <dbname> -X -f gather.sql > ${PTDEST}/out.txt




Hint: You are currently not seeing messages from other users and the system.
      Users in the 'systemd-journal' group can see all messages. Pass -q to
      turn off this notice.
No journal files were opened due to insufficient permissions.

[svcpostgres@pv2medpg1c1 ~]$ tar czvf "/tmp/pt-pgdatacollection-`hostname`.tar.gz" ${PTDEST}
tar: Removing leading `/' from member names

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

select
  name as "Parameter",
  case when setting in ('-1', '0', 'off', 'on') then setting else
    case unit
      when '8kB' then pg_size_pretty(setting::int8 * 8 * 1024)
      when '16MB' then pg_size_pretty(setting::int8 * 16 * 1024 * 1024)
      when 'kB' then pg_size_pretty(setting::int8 * 1024)
      else setting || coalesce ('', ' ' || unit)
    end
  end as "Value",
  case when boot_val in ('-1', '0', 'off', 'on') then boot_val else
    case unit
      when '8kB' then pg_size_pretty(boot_val::int8 * 8 * 1024)
      when '16MB' then pg_size_pretty(boot_val::int8 * 16 * 1024 * 1024)
      when 'kB' then pg_size_pretty(boot_val::int8 * 1024)
      else boot_val || coalesce ('', ' ' || unit)
    end
  end as "Default",
  category as "Category"
from pg_settings
where
  name in (
    'max_connections',
    'shared_buffers',
    'effective_cache_size',
    'maintenance_work_mem',
    'work_mem',
    'min_wal_size',
    'max_wal_size',
    'checkpoint_completion_target',
    'wal_buffers',
    'default_statistics_target',
    'random_page_cost',
    'effective_io_concurrency',
    'max_worker_processes',
    'max_parallel_workers_per_gather',
    'log_destination',
    'logging_collector',
    'log_directory',
    'log_filename',
    'log_truncate_on_rotation',
    'log_rotation_age',
    'log_rotation_size',
    'log_min_duration_statement',
    'log_statement',
    'max_parallel_workers',
    'autovacuum',
    'autovacuum_max_workers',
    'autovacuum_vacuum_scale_factor',
    'autovacuum_vacuum_threshold', 
    'autovacuum_naptime',
    'max_replication_slots',
    'random_page_cost',
    'checkpoint_timeout'
    'seq_page_cost'
  )
order by category, name;


SELECT pg_wal_lsn_diff(pg_current_wal_lsn(), pg_last_wal_replay_lsn()) AS replication_lag;

