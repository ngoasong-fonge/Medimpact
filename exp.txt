Replacing T.IntegerType(), T.BooleanType(), T.DoubleType(), and T.LongType() with varchar(4000) is not ideal if the columns are intended to store numbers or booleans, as this approach sacrifices data type constraints and can lead to inconsistencies (e.g., storing non-numeric data in numeric fields). The appropriate substitutions in PostgreSQL for these data types are:

T.IntegerType() → INTEGER
T.BooleanType() → BOOLEAN
T.DoubleType() → DOUBLE PRECISION
T.LongType() → BIGINT

CREATE TABLE foundry.exposures_by_cycle_period_schema (
    id varchar(4000),
    contract_id varchar(4000),
    contract_organization_id varchar(4000),
    line_of_business varchar(4000),
    source varchar(4000),
    cycle_period_date varchar(4000),
    cycle_period_date_string varchar(4000),
    guarantee_period_id varchar(4000),
    guarantee_period_effective_date varchar(4000),
    guarantee_period_expiration_date varchar(4000),
    plan_year INTEGER,
    level varchar(4000),
    level_order INTEGER,
    level_display_string varchar(4000),
    guarantee_category_type varchar(4000),
    guarantee_category_id varchar(4000),
    guarantee_category_name varchar(4000),
    report_category_id varchar(4000),
    report_category varchar(4000),
    reporting_exclusion_id varchar(4000),
    reporting_exclusion_name varchar(4000),
    carrier_id varchar(4000),
    channel_id varchar(4000),
    channel_name varchar(4000),
    category varchar(4000),
    guarantee_type varchar(4000),
    rate_id varchar(4000),
    contract_executed BOOLEAN,
    contract_effective_date varchar(4000),
    contract_expiration_date varchar(4000),
    first_full_reconciliation_period_start_date varchar(4000),
    contract_annual_reconciliation_length DOUBLE PRECISION,
    contract_co_pay_differential DOUBLE PRECISION,
    contract_eligibility_threshold DOUBLE PRECISION,
    contract_reconciliation_period_length DOUBLE PRECISION,
    rebate_annual_reconciliation_length DOUBLE PRECISION,
    rebate_co_pay_differential DOUBLE PRECISION,
    rebate_reconciliation_period DOUBLE PRECISION,
    contract_eligibility_threshold_basis varchar(4000),
    contract_eligibility_threshold_frequency varchar(4000),
    contract_exposure_cap varchar(4000),
    contract_exposure_cap_basis varchar(4000),
    contract_exposure_offset varchar(4000),
    pharmacy_aggregation_level varchar(4000),
    pharmacy_exposure_cap varchar(4000),
    pharmacy_exposure_cap_basis varchar(4000),
    pharmacy_exposure_offset varchar(4000),
    rebate_aggregation_level varchar(4000),
    rebate_exposure_cap varchar(4000),
    rebate_exposure_cap_basis varchar(4000),
    rebate_exposure_offset varchar(4000),
    rebate_payout_period varchar(4000),
    rebate_pricing_type varchar(4000),
    has_rebate_guarantee_rates BOOLEAN,
    has_rebate_passthrough_rates BOOLEAN,
    net_rx_count BIGINT,
    admin_fee DOUBLE PRECISION,
    incremental_admin_fee DOUBLE PRECISION,
    guaranteed_exposure_exposure_cap DOUBLE PRECISION,
    guaranteed_exposure_no_cap DOUBLE PRECISION,
    guaranteed_exposure DOUBLE PRECISION,
    incremental_guaranteed_exposure DOUBLE PRECISION,
    incremental_guaranteed_exposure_exposure_cap DOUBLE PRECISION,
    incremental_guaranteed_exposure_no_cap DOUBLE PRECISION,
    incremental_net_rx_count BIGINT
);



[svcpostgres@pv2medpg3db1 foundry]$ psql -d archive -c "COPY foundry.task_edited_schema FROM '/opt/backup/foundry/task_edited_extract.csv' DELIMITER '|' CSV HEADER;"
ERROR:  missing data for column "reviewer"
CONTEXT:  COPY task_edited_schema, line 2: "c3c58eeb-5653-4afd-9ed2-7aaa4f481412,c3c58eeb-5653-4afd-9ed2-7aaa4f481412,c3c58eeb-5653-4afd-9ed2-7a..."



Using these native PostgreSQL types will help maintain data integrity and ensure that the columns store the expected data types.



To eliminate the statement: log entries and only keep the AUDIT: entries, you can adjust your PostgreSQL logging settings to stop logging SQL statements for specific users (such as auditor), or you can fine-tune the pg_audit configuration.

Option 1: Modify PostgreSQL log_statement Configuration
Disable log_statement for the auditor user: You can control the verbosity of the log entries for specific users by adjusting the log_statement setting. By default, log_statement is set to all or ddl or mod (depending on your configuration).

You can disable statement logging for the auditor user by setting log_statement to none for that user.

Setting log_statement = 'all' in PostgreSQL is a way to log every SQL statement that is executed, which is useful for auditing and tracking queries.

This setting has the following options:

none: Logs no statements.
ddl: Logs only data definition statements (like CREATE, ALTER, and DROP).
mod: Logs all DDL and data modification statements (like INSERT, UPDATE, DELETE, TRUNCATE).
all: Logs all statements, including SELECT queries.






psql -h pg-prod-1 -U deployadmin -d citus -c "COPY mrg.salesforce_case from '/opt/backup/mrg/caseinc101.csv' with (HEADER, format csv, delimiter ',', null '', force_null(actual_hours__c,lics_level__c,fo_case_closed_date_variance__c,begin_date__c,birth_date__c,closeddate,createddate,datereceived__c,due_date_time__c,duedate__c,e2e_completed_date__c,e2e_start_date__c,first_comment_date__c,last_comment_date__c,lastmodifieddate,ooo_end_date__c,ooo_start_date__c,plus_2_business_days__c,requested_due_date__c,systemmodstamp,x1_minute_delay__c));"

psql -d archive -c "COPY foundry.task_edited_schema FROM '/opt/backup/foundry/task_edited_extract.csv' DELIMITER '|' CSV HEADER;"

CREATE TABLE foundry.task_edited_schema (
    last_modified_by varchar(4000),
    reviewer varchar(4000),
    last_status_changer varchar(4000),
    assigner varchar(4000),
    assignee varchar(4000),
    id varchar(4000),
    category varchar(4000),
    type varchar(4000),
    title varchar(4000),
    description varchar(4000),
    d_timestamp varchar(4000),
    priority varchar(4000),
    status varchar(4000),
    sub_status varchar(4000),
    due_date varchar(4000),
    last_status_change_timestamp varchar(4000),
    last_modified_timestamp varchar(4000),
    review_timestamp varchar(4000),
    linked_entity_id varchar(4000),
    linked_ccm_entity_id varchar(4000),
    linked_entity_ids varchar(4000),
    linked_ccm_entity_ids varchar(4000)
);

when I use '|' error says missing data for column "reviewer" then when I use ',' error says missing data for column "linked_ccm_entity_id"
[svcpostgres@pv2medpg3db1 log]$ psql -d archive -c "COPY foundry.task_edited_schema (last_modified_by, reviewer, last_status_changer, assigner, assignee, id, category, type, title, description, d_timestamp, priority, status, sub_status, due_date, last_status_change_timestamp, last_modified_timestamp, review_timestamp, linked_entity_id, linked_ccm_entity_id, linked_entity_ids, linked_ccm_entity_ids)
FROM '/opt/backup/foundry/task_edited_extract.csv' WITH (FORMAT csv, DELIMITER '|', HEADER true);"
ERROR:  missing data for column "reviewer"
CONTEXT:  COPY task_edited_schema, line 2: "c3c58eeb-5653-4afd-9ed2-7aaa4f481412,c3c58eeb-5653-4afd-9ed2-7aaa4f481412,c3c58eeb-5653-4afd-9ed2-7a..."

[svcpostgres@pv2medpg3db1 log]$ psql -d archive -c "COPY foundry.task_edited_schema (last_modified_by, reviewer, last_status_changer, assigner, assignee, id, category, type, title, description, d_timestamp, priority, status, sub_status, due_date, last_status_change_timestamp, last_modified_timestamp, review_timestamp, linked_entity_id, linked_ccm_entity_id, linked_entity_ids, linked_ccm_entity_ids)
FROM '/opt/backup/foundry/task_edited_extract.csv' WITH (FORMAT csv, DELIMITER ',', HEADER true);"
ERROR:  missing data for column "linked_ccm_entity_id"
CONTEXT:  COPY task_edited_schema, line 136: "23836ae4-9672-4fbd-9928-fecd2a65678f,23836ae4-9672-4fbd-9928-fecd2a65678f,23836ae4-9672-4fbd-9928-fe..."


awk -F',' '{print NF}' /opt/backup/foundry/task_edited_extract.csv | sort | uniq -c

sed -n '136p' /opt/backup/foundry/task_edited_extract.csv



[svcpostgres@pv2medpg3db1 log]$ awk -F',' '{print NF}' /opt/backup/foundry/task_edited_extract.csv | sort | uniq -c
    185 0
    249 1
    128 10
     26 11
      6 12
     91 13
     18 14
     14 15
      8 16
      4 17
      7 18
      6 19
      4 2
      4 20
      2 21
    628 22
     42 23
     51 24
      9 25
      3 26
      1 27
      2 29
      4 3
      1 31
      1 32
      4 4
      2 5
      5 6
      3 9

[svcpostgres@pv2medpg3db1 log]$ sed -n '136p' /opt/backup/foundry/task_edited_extract.csv
23836ae4-9672-4fbd-9928-fecd2a65678f,23836ae4-9672-4fbd-9928-fecd2a65678f,23836ae4-9672-4fbd-9928-fecd2a65678f,23836ae4-9672-4fbd-9928-fecd2a65678f,1a7ec779-d86e-45de-840e-7aa77c764fde,12d57a03-8f1c-4df0-ae4e-08cc0730db90,Contract Review,Task Manager,CHENANGO,"CHENANGO - 2023 - \"Andy 9/10/2023:  Please update specialty channel to be all contracted pharamcies (not just specialty pharmacies).  Please update OTC exclusion to be OTCs other than strips, meters, and medications.  Please update device exclusion to be devices other than strips, meters, and medications.  Please remove rebate non-POS exclusion.  Please remove Most Favored National exclusion.  Please add exclusions for university pharmacies, Home infusion pharmacies, ITU pharmacies, and VA pharmacies.  Please add exclusions for claims older than 180 days.  please add exclusions for invalid identifiers, reversed claism, rejected claims.  Thank you.


Step 4: Update the COPY Command with the Correct Delimiter
Since the file appears to be comma-delimited, you should use , as the delimiter:


Step 5: Handle Missing Data with Default Values (Optional)
If certain columns (like reviewer or linked_ccm_entity_id) may be empty in some rows, consider setting default values in your table schema:
ALTER TABLE foundry.task_edited_schema ALTER COLUMN reviewer SET DEFAULT '';
ALTER TABLE foundry.task_edited_schema ALTER COLUMN linked_ccm_entity_id SET DEFAULT 0;  -- or NULL if appropriate



awk -F',' 'NF == 23' /opt/backup/foundry/task_edited_extract.csv > /opt/backup/foundry/task_edited_filtered.csv


awk -F',' '{print NF}' /opt/backup/foundry/task_edited_filtered.csv | sort | uniq -c

