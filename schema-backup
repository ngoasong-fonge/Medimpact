

#!/bin/bash

# Source the environment file
source /opt/app/localhome/postgres/pg_env.sh

# Specify backup and log file locations
backup_location="/opt/backup"
log_location="/opt/backup/schemabackup_restore_log.txt"
original_schema="mepstg"  # Replace with your original schema name
new_schema="newngmep"    # Replace with your desired new schema name

# Record the start time
start_time=$(date +"%Y-%m-%d %H:%M:%S")

# Backup the schema to /opt/backup
pg_dump -h localhost -U deployadmin -d citus -n mepstg --schema="$original_schema" > "$backup_location/mepstg_schema_backup.sql"

# Replace the original schema name with the new schema name in the SQL file
sed -i "s/$original_schema/$new_schema/g" "$backup_location/mepstg_schema_backup.sql"

# Drop target schema if already exists
psql -h localhost -U deployadmin -d citus -c "DROP SCHEMA IF EXISTS $new_schema CASCADE;"

# Create the target schema
psql -h localhost -U deployadmin -d citus -c "CREATE SCHEMA IF NOT EXISTS $new_schema;"

# Restore the schema within the same database using psql
psql -h localhost -U deployadmin -d citus -f "$backup_location/mepstg_schema_backup.sql"

# Check the status of the restore operation
if [ $? -eq 0 ]; then
  echo "Restore completed successfully."
else
  echo "Error: Restore operation failed."
fi

# Record the completion time
end_time=$(date +"%Y-%m-%d %H:%M:%S")

# Output the start and completion times to a log file
echo "Start Time: $start_time" > "$log_location"
echo "Completion Time: $end_time" >> "$log_location"

# Display the log file path
echo "Backup and restore completed. Log file: $log_location"

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
The bellow script does backup , restore and analyze verbose the tables at the end
----------------------------------------------------------------------------------------------------------------------------------------------------

#!/bin/bash

# Source the environment file
source /opt/app/localhome/postgres/pg_env.sh

# Specify backup and log file locations
backup_location="/opt/backup"
log_location="/opt/backup/schemabackup_restore_log.txt"
original_schema="mepstg"  # Replace with your original schema name
new_schema="newmepstg"    # Replace with your desired new schema name

# Record the start time
start_time=$(date +"%Y%m%d%H%M%S")
backup_file="$backup_location/mepstg_schema_backup_$start_time.sql"

# Backup the schema
pg_dump -h localhost -U deployadmin -d citus -n "$original_schema" --schema="$original_schema" > "$backup_file"

# Replace the original schema name with the new schema name in the SQL file
sed -i "s/$original_schema/$new_schema/g" "$backup_file"

# Drop target schema if already exists
psql -h localhost -U deployadmin -d citus -c "DROP SCHEMA IF EXISTS $new_schema CASCADE;"

# Create the target schema
psql -h localhost -U deployadmin -d citus -c "CREATE SCHEMA IF NOT EXISTS $new_schema;"

# Restore the schema within the same database using psql
psql -h localhost -U deployadmin -d citus -f "$backup_file"

# Check the status of the restore operation
if [ $? -eq 0 ]; then
  echo "Restore completed successfully."
else
  echo "Error: Restore operation failed."
fi

# Analyze the tables within the restored schema
tables_to_analyze=$(psql -h localhost -U deployadmin -d citus -t -c "SELECT table_name FROM information_schema.tables WHERE table_schema = '$new_schema';")
for table in $tables_to_analyze; do
  psql -h localhost -U deployadmin -d citus -c "ANALYZE VERBOSE $new_schema.$table;"
done

# Record the completion time
end_time=$(date +"%Y-%m-%d %H:%M:%S")

# Output the start and completion times to a log file
echo "Start Time: $start_time" > "$log_location"
echo "Completion Time: $end_time" >> "$log_location"

# Display the log file path
echo "Backup, restore, and analyze completed. Log file: $log_location"

-------------------------------------------------------------------------------------------------------------------------------------------------------------
Bellow is a script that does backup of just original schema with .sql format
----------------------------------------------------------------------------------------------------------------------------------------------------
#!/bin/bash

# Source the environment file
source /opt/app/localhome/svcpostgres/pg_env.sh

# Specify backup and log file locations
backup_location="/opt/backup"
log_location="/opt/backup/schemabackup_log.txt"
original_schema="ngmep"  # Replace with your original schema name

# Record the start time
start_time=$(date +"%Y-%m-%d %H:%M:%S")

# Backup the schema without parallelism
pg_dump -h localhost -U deployadmin -d citus -n "$original_schema" --schema="$original_schema" > "$backup_location/$original_schema"_backup.sql

# Check the status of the backup operation
if [ $? -eq 0 ]; then
  echo "Backup completed successfully."
else
  echo "Error: Backup operation failed."
fi

# Record the completion time
end_time=$(date +"%Y-%m-%d %H:%M:%S")

# Output the start and completion times to a log file
echo "Start Time: $start_time" > "$log_location"
echo "Completion Time: $end_time" >> "$log_location"

# Display the log file path
echo "Backup completed. Log file: $log_location"


---------------------------------------------------------------------------------------------------------------------------------------------------
The script bellow will create the schema with a new name by using sed command
--------------------------------------------------------------------------------------------------------------

#!/bin/bash

# Source the environment file
source /opt/app/localhome/svcpostgres/pg_env.sh

# Specify backup file location
backup_location="/opt/backup"
log_location="/opt/backup/restore_log.txt"
original_schema="ngmep"  # Replace with your original schema name
new_schema="newngmep"    # Replace with your desired new schema name

# Record the start time
start_time=$(date +"%Y-%m-%d %H:%M:%S")

# Drop the target schema if it already exists
psql -h localhost -U deployadmin -d citus -c "DROP SCHEMA IF EXISTS $new_schema CASCADE"

# Create the target schema
psql -h localhost -U deployadmin -d citus -c "CREATE SCHEMA IF NOT EXISTS $new_schema;"

# Replace the original schema name with the new schema name in the SQL file
backup_file="$backup_location/$original_schema"_backup.sql
sed -i "s/$original_schema/$new_schema/g" "$backup_file"

# Restore the schema using psql with a new schema name
psql -h localhost -U deployadmin -d citus -f "$backup_file" -v new_schema="$new_schema"

# Check the status of the restore operation
if [ $? -eq 0 ]; then
  echo "Restore completed successfully."
else
  echo "Error: Restore operation failed."
fi

# Record the completion time
end_time=$(date +"%Y-%m-%d %H:%M:%S")

# Output the start and completion times to the log file
echo "Start Time: $start_time" > "$log_location"
echo "Completion Time: $end_time" >> "$log_location"

# Display the log file path
echo "Restore completed. Log file: $log_location"

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
The Script bellow restores the .sql backup without sed 
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
#!/bin/bash

# Source the environment file
source /opt/app/localhome/svcpostgres/pg_env.sh

# Specify backup file location
backup_location="/opt/backup"
log_location="/opt/backup/restore_log.txt"
target_schema="ngmep"  # Replace with your desired schema name

# Record the start time
start_time=$(date +"%Y-%m-%d %H:%M:%S")

# Drop the target schema if it already exists
psql -h localhost -U deployadmin -d citus -c "DROP SCHEMA IF EXISTS newngmep CASCADE"

# Create the target schema
psql -h localhost -U deployadmin -d citus -c "CREATE SCHEMA IF NOT EXISTS newngmep;"

# Restore the schema using psql
psql -h localhost -U deployadmin -d citus -f "$backup_location/$target_schema"_backup.sql

# Check the status of the restore operation
if [ $? -eq 0 ]; then
  echo "Restore completed successfully."
else
  echo "Error: Restore operation failed."
fi

# Record the completion time
end_time=$(date +"%Y-%m-%d %H:%M:%S")

# Output the start and completion times to the log file
{
  echo "Start Time: $start_time"
  echo "Completion Time: $end_time"
} > "$log_location"

# Display the log file path
echo "Restore completed. Log file: $log_location"



-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Compression: The custom dump format supports compression, which can significantly reduce the size of the backup file.
You can use the -Fc option with pg_dump to create a custom-format dump file with compression.
The resulting .dump file will likely be smaller compared to an equivalent plain SQL script (.sql) file.
Performance: The custom dump format is more efficient in terms of both backup and restore operations. 
It can capture the database structure, data, and additional metadata in a binary format, making it faster for large databases.
Comprehensive Backup: The custom dump format includes additional information such as indexes, functions, and more, providing a more comprehensive backup of the entire schema.
If you are specifically looking to backup the entire schema (including data, indexes, etc.), the custom dump format is well-suited for this purpose.

find /path/to/wal_archive -type f -name "*.pg_wal" -mtime +5 -exec rm {} \;
----------------------------------------------------------------------------------------------------------------------------------------------------
pg_dump -h localhost -U postgres -d citus -n custom_schema | gzip > backup.dump.gz
gunzip -c backup.dump.gz | sed 's/custom_schema/npmeg_schema/g'	 > modified_backup.dump
psql -h localhost -U postgres -d citus -f modified_backup.dump

-------------------------------------- This bellow worked because its plain text backup not binary using psql to res ----------------------
pg_dump -h localhost -U postgres -d citus -n custom_schema > backup.dump
sed 's/custom_schema/ngmep_schema/g' backup.dump > modified_backup.dump
psql -h localhost -U postgres -d citus -f modified_backup.dump
---------------------------------------------------------------------------------------------------------------------------
pg_restore -h localhost -U postgres -d citus -j <number_of_parallel_jobs> -Fc -c -v backup.dump.gz



------------ I didn't sed and the backup and restore worked---This is Fc Binary format---- But when I sed the binary and try to use pg_restore its fails and also pqsl won't work because its not plain text backup

pg_dump -h localhost -U postgres -d citus -n custom_schema -Fc > binary_backup.dump
pg_restore -h localhost -U postgres -d citus -v binary_backup.dump

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

--------------------------------------------------------taking schema backup then overright old backup------------------------------------------------------------------------------------------------------------
After the backup operation, it checks the number of existing backup files. If there are more than two, it finds and removes the oldest one.
This modification ensures that you keep at least two copies of the _backup.sql file while overwriting the oldest one. 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#!/bin/bash

# Source the environment file
source /opt/app/localhome/svcpostgres/pg_env.sh

# Specify backup and log file locations
backup_location="/opt/backup/overwrite_backup"
log_location="/opt/backup/schemabackup_log.txt"
original_schema="mepstg"  # Replace with your original schema name

# Record the start time
start_time=$(date +"%Y-%m-%d %H:%M:%S")

# Backup the schema without parallelism
pg_dump -h localhost -U deployadmin -d citus -n "$original_schema" --schema="$original_schema" > "$backup_location/$original_schema"_backup_new.sql

# Check the status of the backup operation
if [ $? -eq 0 ]; then
  echo "Backup completed successfully."
else
  echo "Error: Backup operation failed."
fi

# Keep at least two copies of the backup, overwriting the oldest
backup_count=$(ls -1 "$backup_location"/*_backup*.sql | wc -l)
if [ "$backup_count" -gt 1 ]; then
  oldest_backup=$(ls -1t "$backup_location"/*_backup*.sql | tail -n 1)
  rm "$oldest_backup"
fi

# Record the completion time
end_time=$(date +"%Y-%m-%d %H:%M:%S")

# Output the start and completion times to a log file
echo "Start Time: $start_time" > "$log_location"
echo "Completion Time: $end_time" >> "$log_location"

# Display the log file path
echo "Backup completed. Log file: $log_location"

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
To modify your restore script to use the new backup file, you need to pass the file path of the new backup file to the script. You can modify the script to accept the backup file path as an argument
the script expects the backup file name to have the suffix "_backup_new.sql." When running the script, provide the full path to the backup file as an argument:

./restore_script.sh /opt/backup/mepstg_backup_new.sql

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#!/bin/bash

# Source the environment file
source /opt/app/localhome/svcpostgres/pg_env.sh

# Specify backup file location
log_location="/opt/backup/restore_log.txt"
original_schema="ngmep"  # Replace with your original schema name
new_schema="newngmep"    # Replace with your desired new schema name

# Check if the backup file path is provided as an argument
if [ "$#" -ne 1 ]; then
  echo "Error: Please provide the path to the backup file."
  exit 1
fi

# Assign the backup file path from the argument
backup_file="$1"

# Record the start time
start_time=$(date +"%Y-%m-%d %H:%M:%S")

# Drop the target schema if it already exists
psql -h localhost -U deployadmin -d citus -c "DROP SCHEMA IF EXISTS $new_schema CASCADE"

# Create the target schema
psql -h localhost -U deployadmin -d citus -c "CREATE SCHEMA IF NOT EXISTS $new_schema;"

# Replace the original schema name with the new schema name in the SQL file
sed -i "s/$original_schema/$new_schema/g" "$backup_file"

# Restore the schema using psql with a new schema name
psql -h localhost -U deployadmin -d citus -f "$backup_file" -v new_schema="$new_schema"

# Check the status of the restore operation
if [ $? -eq 0 ]; then
  echo "Restore completed successfully."
else
  echo "Error: Restore operation failed."
fi

# Record the completion time
end_time=$(date +"%Y-%m-%d %H:%M:%S")

# Output the start and completion times to the log file
echo "Start Time: $start_time" > "$log_location"
echo "Completion Time: $end_time" >> "$log_location"

# Display the log file path
echo "Restore completed. Log file: $log_location"
